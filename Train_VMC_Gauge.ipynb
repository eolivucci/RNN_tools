{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of pRNN ansatz for generation of Symmetric Polynomials\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) #stop displaying tensorflow warnings\n",
    "\n",
    "import importnb\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with importnb.Notebook('pRNN_homo_sample.ipynb'):\n",
    "    from pRNN_homo_sample import RNNWavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes local energies given a set of computational basis vectors sampled according to the pRNN wavefunction probability\n",
    "\n",
    "def symPoly_local_energies(a,b,Nc, samples, model):\n",
    "    \"\"\" Local energies of a system of Nc**2 interacting bosonic oscillators.\n",
    "    Returns: The local energies that correspond to the \"samples\"\n",
    "    Inputs:\n",
    "    - a,b: define the Gauge generator\n",
    "    - Nc: rank of the matrix group\n",
    "    - samples: (numsamples, Nc**2)\n",
    "    - model: The RNN wavefunction model instance\n",
    "    \"\"\"\n",
    "\n",
    "    numsamples = samples.shape[0]  # Extracts number of samples\n",
    "\n",
    "    local_energies = np.zeros((numsamples), dtype=np.float64)  # Initialize local energy to zero for each sample\n",
    "    \n",
    "    energy_samples= np.zeros((2*Nc,numsamples), dtype=np.float64) # Array of energies to zero for each sample\n",
    "    queue_samples= np.zeros((1+2*Nc,numsamples,Nc*Nc), dtype=np.float64)  # Array of vector states to zero for each sample\n",
    "    log_probs= np.zeros((1+2*Nc)*numsamples, dtype=np.float64) # Array of log probs for each vector state for each sample\n",
    "    \n",
    "    queue_samples[0]=samples\n",
    "\n",
    "    hmagnetic = 300 # Magnetic field to tesy symmetry-breaking\n",
    "    \n",
    "    # Evaluation of local energy\n",
    "\n",
    "    for c in range(Nc):  # +1 terms\n",
    "        samplesT = np.copy(samples) #copy samples to generate new vectors\n",
    "\n",
    "        energy_samples[c,:]= samplesT[:, (a-1)*Nc+c]\n",
    "        #print(samplesT)\n",
    "        #print(energy_samples[c,:])\n",
    "        \n",
    "        samplesT[:, (a-1)*Nc+c] -= 1 # One excitation hops away from site (a,c)\n",
    "        samplesT[:, (b-1)*Nc+c] += 1 # One excitation hops in to site (b,c)\n",
    "        \n",
    "        queue_samples[1+c] = samplesT\n",
    "\n",
    "    for c in range(Nc):  # -1 terms\n",
    "        samplesT = np.copy(samples)\n",
    "        \n",
    "        energy_samples[c,:] = - samplesT[:, c*Nc+(b-1)]\n",
    "        \n",
    "        samplesT[:, c*Nc+(b-1)] -= 1 # One excitation hops away from site (c,b)\n",
    "        samplesT[:, c*Nc+(a-1)] += 1 # One excitation hops in to site (c,a)\n",
    "        \n",
    "        queue_samples[1+Nc+c] = samplesT\n",
    "\n",
    "    # Evaluate log probability of samples and of flipped sample vectors, according to pRNN amplitudes\n",
    "    \n",
    "    queue_samples_reshaped = np.reshape(queue_samples, [(1+2*Nc) * numsamples, Nc*Nc])\n",
    "    len_sigmas = queue_samples_reshaped.shape[0]\n",
    "\n",
    "    steps = np.ceil(len_sigmas / 25000)  # Maximum of 25000 configurations in batch size for memory reasons\n",
    "\n",
    "    for i in range(int(steps)):\n",
    "        cut = slice((i * len_sigmas) // int(steps), ((i + 1) * len_sigmas) // int(steps))\n",
    "        log_probs[cut] = model.log_probability(queue_samples_reshaped[cut]) # Computes log probabilities slice-by-slice\n",
    "\n",
    "    log_probs_reshaped = np.reshape(log_probs,[1+2*Nc,numsamples]) # Reshape log_probs putting in line all log probs related to a given sample\n",
    "    #print(\"Here: we expect all coinciding: \"+str(log_probs_reshaped))\n",
    "    amplitudes_ratio = np.exp(0.5 * log_probs_reshaped[1:, :] - 0.5 * log_probs_reshaped[0, :]) #Ratio of wavefunction amplitudes for each flipped over unflipped sample\n",
    "\n",
    "    local_energies += np.sum(energy_samples*amplitudes_ratio,axis=0) # Adds up all local energy terms \n",
    "\n",
    "    return local_energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of pRNN with VMC for energy minimization\n",
    "# Uses Adam optimizer\n",
    "# Uses gradient decay\n",
    "\n",
    "def train_rnn_wavefunction(model, Nc, num_epochs, learning_rate, num_samples):\n",
    "    \"\"\"\n",
    "    Train the RNN wavefunction model to minimize the local energy.\n",
    "    Parameters:\n",
    "    - model: RNN-based wavefunction model\n",
    "    - Nc rank of matrices (Nc*Nc matrix elements =  bosonic oscillators = variables in the polynomial)\n",
    "    - num_epochs: int, number of training epochs\n",
    "    - learning_rate: float, learning rate for optimization\n",
    "    - num_samples: int, total number of samples per epoch\n",
    "    \"\"\"\n",
    "    # Define initial learning rate, decay rate, and decay steps\n",
    "    initial_learning_rate = learning_rate\n",
    "    decay_rate = 0.5\n",
    "    decay_steps = 250  # The step interval at which the learning rate is updated\n",
    "\n",
    "    # Create an exponential decay schedule\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=False  # If True, decay happens in discrete steps\n",
    "    )\n",
    "\n",
    "    # Use the schedule in an optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    energy_vec = [] # Stores avg energies during optimization for plot\n",
    "    std_vec = [] # Stores std devs during optimization for plot\n",
    "    avg_magnetization = [] # Stores average spin vector during optimization for plot\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        samples = model.sample(num_samples)  # Generate num_samples samples from the RNN wavefunction\n",
    "\n",
    "        random_array =np.random.rand(Nc*Nc)\n",
    "        local_energies= np.array([tf.cast(random_array[(a-1)*Nc+b]*symPoly_local_energies(a,b,Nc,samples, model), dtype=tf.float32) for b in range(Nc) for a in range(Nc)]) # Compute local energy for every sample\n",
    "        \n",
    "        #local_energies= tf.cast(symPoly_local_energies(2,2,Nc,samples, model), dtype=tf.float32)+0.6*tf.cast(symPoly_local_energies(1,1,Nc,samples, model), dtype=tf.float32) \n",
    " \n",
    "        with tf.GradientTape() as tape:\n",
    "            log_probs = model.log_probability(samples)\n",
    "            loss = tf.abs(tf.abs(tf.reduce_mean(log_probs * local_energies))-tf.abs(tf.reduce_mean(log_probs))*tf.abs(tf.reduce_mean(local_energies))) # Energy minimization loss\n",
    "            #print(\"loss function evaluates to: \"+str(loss))\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "        avg_energy = np.mean(local_energies)\n",
    "        std_energy = np.std(local_energies)\n",
    "        \n",
    "        energy_vec.append(avg_energy)\n",
    "        std_vec.append(std_energy)\n",
    "        avg_magnetization.append(np.mean(tf.reshape(samples,[-1])))\n",
    "        \n",
    "        #print(f\"Epoch {epoch + 1}/{num_epochs}, Energy: {avg_energy:.6f}, Std Dev: {std_energy:.6f}, Mean Spin: {np.mean(samples):.6f}\")\n",
    "\n",
    "            #if epoch % 50 ==0:\n",
    "            #    print(\"Time step = \"+str(epoch) )\n",
    "        #if epoch == num_epochs-1:\n",
    "            #print(np.mean(samples,axis=0))\n",
    "        \n",
    "    return energy_vec, std_vec , avg_magnetization, np.mean(samples,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0.]\n",
      "[0. 0. 0. 2.]\n",
      "[0.   0.68 0.4  0.92]\n",
      "[0. 0. 0. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Define the system size (number of timesteps), number of GRU units, and other parameters\n",
    "Nc = 2 # Gauge group rank\n",
    "\n",
    "system_size = Nc*Nc # Number of time steps = spin sites\n",
    "system_charge =  2 # Polynomial degree (= power of matrix)\n",
    "units = 20  # Number of (hidden) units in the GRU layer\n",
    "input_dim = system_charge+1  # Input dimension (e.g., spin-1/2 system)\n",
    "output_dim = system_charge+1  # Output dimension (e.g., 2 possible states per timestep)\n",
    "seed = 111\n",
    "\n",
    "\n",
    "# Generate random samples\n",
    "numsamples = 50\n",
    "\n",
    "# Create the RNNWavefunction model\n",
    "rnn_wavefunction = RNNWavefunction(system_size=Nc*Nc, units=units, input_dim=input_dim, output_dim=output_dim,seed =seed)\n",
    "\n",
    "#samples = rnn_wavefunction.sample(numsamples)\n",
    "\n",
    "analysis_vector =np.zeros((Nc*Nc,numsamples))\n",
    "\n",
    "for i in range(4):\n",
    "    rnn_wavefunction = RNNWavefunction(system_size=Nc*Nc, units=units, input_dim=input_dim, output_dim=output_dim,seed =seed)\n",
    "    energies, std_devs, order_param, last_sample = train_rnn_wavefunction(rnn_wavefunction,Nc, num_epochs=100,learning_rate= 0.5,num_samples=numsamples)\n",
    "    print(last_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
