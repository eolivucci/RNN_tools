{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pRNN wavefunction ansazt with GRU layer + Dense softmax\n",
    "# Samples homogeneous monomials in Nc^2 and fixed degree \n",
    "# Needs to be fixed by broadcasting\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RNNWavefunction(tf.keras.Model):\n",
    "    def __init__(self, system_size, units=20, input_dim=3, output_dim=3, seed=211):\n",
    "        \"\"\"\n",
    "        system_size: int, number of timesteps or system size (= number of monomial variables)\n",
    "        units: int, number of units in the GRU layer\n",
    "        input_dim: int, number of input features (= monomial homogeneous degree = charge+1)\n",
    "        output_dim: int, number of output features (= monomial homogeneous degree = charge+1)\n",
    "        seed: int, the random seed for reproducibility\n",
    "        \"\"\"\n",
    "        super(RNNWavefunction, self).__init__()\n",
    "\n",
    "        # Set random seeds for reproducibility\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "        self.system_size = system_size\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Define the GRU layer (one GRU layer with specified units)\n",
    "        self.gru = tf.keras.layers.GRU(units=units, return_sequences=True, return_state=True)\n",
    "        \n",
    "        # Final Dense layer with Softmax output (probabilities, not logits!)\n",
    "        self.dense = tf.keras.layers.Dense(output_dim, activation=\"softmax\")\n",
    "        \n",
    "    def call(self, inputs, hidden_state=None, training=False):\n",
    "        \"\"\"\n",
    "        Forward pass through the network with fixed hidden state.\n",
    "        \"\"\"\n",
    "        if hidden_state is None:\n",
    "            hidden_state = tf.zeros((inputs.shape[0], self.gru.units))  # Fixed hidden state\n",
    "\n",
    "        x, hidden_state = self.gru(inputs, initial_state=hidden_state, training=training)  # GRU layer\n",
    "        x = self.dense(x)  # Apply Dense layer\n",
    "\n",
    "        return x, hidden_state\n",
    "\n",
    "    def sample(self, numsamples):\n",
    "\n",
    "        \"\"\"\n",
    "        Generate samples from the probability distribution parameterized by the RNN.\n",
    "        numsamples: int, number of samples to generate\n",
    "        \"\"\"\n",
    "        samples = []  # List to store the generated sequence\n",
    "        inputs = tf.zeros((numsamples, 1, self.input_dim), dtype=tf.float32)  # Initial input (zero vector)\n",
    "        hidden_state = None  # No initial hidden state\n",
    "\n",
    "        for t in range(self.system_size-1): # Sampling cycle over system_size =  number of variables\n",
    "            output, hidden_state = self.call(inputs, hidden_state=hidden_state)  # Forward pass through the model\n",
    "\n",
    "            # Get probabilities for the last generated timestep\n",
    "            softout= output[:, -1, :]  # Shape: [numsamples, output_dim]\n",
    "            #print(\"Sample is now = \"+str(samples))\n",
    "            # Projection of softmax probabilities imposing charge conservation\n",
    "            softout_t = np.copy(softout)\n",
    "            #print(\"Starting with softout_t = \"+str(softout))\n",
    "            thetavec = [np.heaviside(self.input_dim-1-np.sum(np.array(samples),axis=0)-i,1) for i in range(softout_t.shape[1])]\n",
    "            #print(\"Apply projection thetavec = \"+str(thetavec))\n",
    "            softout_t = np.array([softout_t[:,i]*thetavec[i] for i in range(softout_t.shape[1])])\n",
    "\n",
    "            #norms = np.sum(softout_t,axis=0)\n",
    "            #print(\"Normalize = \"+str(softout_t))\n",
    "            #print(\"by norm vec = \"+str(norms))\n",
    "            softout_t = np.transpose(softout_t)\n",
    "            #print(softout_t / np.sum(softout_t, axis=1, keepdims=True))\n",
    "            \n",
    "\n",
    "            # Sample from categorical distribution\n",
    "        \n",
    "            sampled_t = tf.random.categorical(tf.math.log(softout_t), num_samples=1)  # Shape: [numsamples, 1]\n",
    "            sampled_t = tf.squeeze(sampled_t, axis=-1)  # Shape: [numsamples]\n",
    "        \n",
    "            # Append sampled values to the list\n",
    "            samples.append(sampled_t)\n",
    "        \n",
    "            # Convert sampled values to one-hot encoding for the next input\n",
    "            inputs = tf.one_hot(sampled_t, depth=self.output_dim, dtype=tf.float32)\n",
    "            inputs = tf.expand_dims(inputs, axis=1)  # Add time-step dimension\n",
    "            \n",
    "        samples = tf.stack(samples, axis=1)\n",
    "\n",
    "        J = tf.constant((self.input_dim-1)*np.ones(samples.shape[0])-np.sum(samples,axis=1))\n",
    "        J = np.transpose(tf.cast(tf.expand_dims(J, axis=0), dtype = tf.int64))\n",
    "        #print(samples)\n",
    "        #print(J)\n",
    "        samples = tf.concat([samples, J], axis=1)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def log_probability(self, samples):\n",
    "        \"\"\"\n",
    "        Calculate log-probabilities of the given samples.\n",
    "        samples: Tensor, shape (numsamples, system_size), the sampled wavefunction\n",
    "        \"\"\"\n",
    "        # Convert samples to one-hot encoding\n",
    "        one_hot_samples = tf.one_hot(samples, depth=self.output_dim, dtype=tf.float32)\n",
    "\n",
    "        inputs = one_hot_samples  # Shape: [numsamples, system_size, output_dim]\n",
    "    \n",
    "        # Ensure evaluation mode (training=False)\n",
    "        probs, _ = self.call(inputs, training=False)  # Forward pass through the model with training=False\n",
    "        \n",
    "        # Compute log probabilities (log(p(x)))\n",
    "        log_probs = tf.reduce_sum(tf.math.log(tf.reduce_sum(tf.multiply(probs, one_hot_samples), axis=-1)), axis=-1)\n",
    "\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 4  5  1  0]\n",
      " [ 5  4  0  1]\n",
      " [ 1  3  0  6]\n",
      " [ 7  2  1  0]\n",
      " [ 3  4  3  0]\n",
      " [ 3  5  1  1]\n",
      " [10  0  0  0]\n",
      " [ 2  5  1  2]\n",
      " [ 4  4  2  0]\n",
      " [ 5  0  1  4]], shape=(10, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "Nc = 2  \n",
    "system_size = Nc*Nc # Number of timesteps\n",
    "charge = 10 # Polynomial Degree\n",
    "input_dim = charge+1  # Number of input features = total charge\n",
    "output_dim = charge+1   # Number of output classes = total charge\n",
    "units = 1     # Number of\n",
    "# GRU units\n",
    "numsamples = 10  # Number of samples to generate\n",
    "seed = 221      # Random seed for reproducibility\n",
    "\n",
    "# Instantiate the RNNWavefunction model\n",
    "model = RNNWavefunction(system_size, units, input_dim, output_dim, seed=np.random.randint(1,100))\n",
    "\n",
    "# Example: Sampling\n",
    "samples = model.sample(numsamples)\n",
    "print(samples)\n",
    "#print(f\"Generated Samples:\\n{samples.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symPoly_local_energies(a,b,Nc, samples, model):\n",
    "    \"\"\" Local energies of a system of Nc**2 interacting bosonic oscillators.\n",
    "    Returns: The local energies that correspond to the \"samples\"\n",
    "    Inputs:\n",
    "    - a,b: define the Gauge generator\n",
    "    - Nc: rank of the matrix group\n",
    "    - samples: (numsamples, Nc**2)\n",
    "    - model: The RNN wavefunction model instance\n",
    "    \"\"\"\n",
    "\n",
    "    numsamples = samples.shape[0]  # Extracts number of samples\n",
    "\n",
    "    local_energies = np.zeros((numsamples), dtype=np.float64)  # Initialize local energy to zero for each sample\n",
    "    \n",
    "    energy_samples= np.zeros((2*Nc,numsamples), dtype=np.float64) # Array of energies to zero for each sample\n",
    "    #print(energy_samples)\n",
    "    queue_samples= np.zeros((1+2*Nc,numsamples,Nc*Nc), dtype=np.float64)  # Array of vector states to zero for each sample\n",
    "    log_probs= np.zeros((1+2*Nc)*numsamples, dtype=np.float64) # Array of log probs for each vector state for each sample\n",
    "    \n",
    "    #print(samples.shape)\n",
    "    #print(queue_samples[0].shape)\n",
    "    queue_samples[0]=samples\n",
    "\n",
    "    # Evaluation of local energy\n",
    "\n",
    "    for c in range(Nc):  # +1 terms\n",
    "        samplesT = np.copy(samples)\n",
    "        \n",
    "        energy_samples[c,:][samples[:, (a-1)*Nc+c] > 0]= 1\n",
    "        energy_samples[c,:][samples[:, (a-1)*Nc+c] == 0]= 0\n",
    "\n",
    "        #print(energy_samples[c,:])\n",
    "        \n",
    "        samplesT[:, (a-1)*Nc+c] -= 1\n",
    "        samplesT[:, (b-1)*Nc+c] += 1\n",
    "        \n",
    "        queue_samples[1+c] = samplesT\n",
    "\n",
    "    for c in range(Nc):  # -1 terms\n",
    "        samplesT = np.copy(samples)\n",
    "\n",
    "        energy_samples[c+Nc,:][samples[:, c*Nc+(b-1)] > 0]= -1\n",
    "        energy_samples[c+Nc,:][samples[:, c*Nc+(b-1)] == 0]= 0\n",
    "        \n",
    "        #print(energy_samples[c+Nc,:])\n",
    "        \n",
    "        samplesT[:, c*Nc+(a-1)] += 1\n",
    "        samplesT[:, c*Nc+(b-1)] -= 1\n",
    "        \n",
    "        queue_samples[1+Nc+c] = samplesT\n",
    " \n",
    "    # Evaluate log probability of samples and of flipped sample vectors, according to pRNN amplitudes\n",
    "    \n",
    "    queue_samples_reshaped = np.reshape(queue_samples, [(1+2*Nc) * numsamples, Nc*Nc])\n",
    "    len_sigmas = queue_samples_reshaped.shape[0]\n",
    "\n",
    "    steps = np.ceil(len_sigmas / 25000)  # Maximum of 25000 configurations in batch size for memory reasons\n",
    "\n",
    "    for i in range(int(steps)):\n",
    "        cut = slice((i * len_sigmas) // int(steps), ((i + 1) * len_sigmas) // int(steps))\n",
    "        log_probs[cut] = model.log_probability(queue_samples_reshaped[cut]) # Computes log probabilities slice-by-slice\n",
    "\n",
    "    log_probs_reshaped = np.reshape(log_probs,[1+2*Nc,numsamples]) # Reshape log_probs putting in line all log probs related to a given sample\n",
    "    amplitudes_ratio = np.exp(0.5 * log_probs_reshaped[1:, :] - 0.5 * log_probs_reshaped[0, :]) #Ratio of wavefunction amplitudes for each flipped over unflipped sample\n",
    "\n",
    "    local_energies += np.sum(energy_samples*amplitudes_ratio,axis=0) # Adds local energy from non-diagonal terms \n",
    "\n",
    "    return local_energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize = [[0.33333334]\n",
      " [0.33333334]\n",
      " [0.33333334]]\n",
      "by norm vec = [1.]\n",
      "[[0.33333334 0.33333334 0.33333334]]\n",
      "Normalize = [[0.30364725]\n",
      " [0.35484487]\n",
      " [0.        ]]\n",
      "by norm vec = [0.6584921]\n",
      "[[0.46112514 0.5388749  0.        ]]\n",
      "Normalize = [[0.25570488]\n",
      " [0.39163306]\n",
      " [0.        ]]\n",
      "by norm vec = [0.6473379]\n",
      "[[0.3950099 0.6049901 0.       ]]\n",
      "tf.Tensor([[2 0 0]], shape=(1, 3), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
